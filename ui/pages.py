"""
P√°ginas principales de la aplicaci√≥n.
"""
import streamlit as st
import pandas as pd
import logging
from typing import Dict, List, Any, Optional

from ui.sidebar import render_sidebar
from ui.components import (
    upload_area, 
    display_example_dataframe, 
    display_instructions,
    progress_tracker,
    metrics_display,
    results_tabs,
    error_message
)
from utils.data_processing import (
    validate_and_prepare_dataframe,
    split_dataframe_into_chunks,
    calculate_total_tokens
)
from utils.metrics_extraction import extract_metrics_from_analysis, extract_key_sections
from utils.visualization import format_analysis_sections
from services.openai_service import openai_service
from services.file_service import file_service

# Configurar logger
logger = logging.getLogger(__name__)

def render_main_page() -> None:
    """Renderiza la p√°gina principal de la aplicaci√≥n."""
    # T√≠tulo y descripci√≥n
    st.title("üìä An√°lisis de Sentimiento de Comentarios")
    st.markdown("### Analiza comentarios de clientes usando modelos de razonamiento avanzado")
    
    # Cargar configuraci√≥n desde la barra lateral
    config = render_sidebar()
    
    # √Årea para subir archivo
    uploaded_file = st.file_uploader(
        "Arrastra y suelta tu archivo CSV con comentarios", 
        type=["csv"], 
        help="El archivo debe contener una columna 'Cuerpo' con los comentarios"
    )
    
    if not uploaded_file:
        # Mostrar √°rea de subida y ejemplo
        upload_area(help_text="El archivo debe contener una columna llamada 'Cuerpo' con los comentarios de los clientes")
        display_example_dataframe()
        display_instructions()
        return
    
    # Procesar archivo subido
    try:
        # Cargar DataFrame
        df = pd.read_csv(uploaded_file)
        
        # Validar y preparar datos
        success, message, df_cleaned = validate_and_prepare_dataframe(df, comment_column="Cuerpo")
        
        if not success:
            st.error(message)
            return
        
        # Mostrar vista previa
        total_comments = len(df_cleaned)
        st.markdown(f"### üìã Vista previa ({total_comments} comentarios)")
        st.dataframe(df_cleaned.head(5), hide_index=True)
        
        # Bot√≥n para iniciar an√°lisis
        if st.button("üîç Analizar comentarios", type="primary"):
            if not config['api_key_status']:
                st.error("Por favor, configura tu API Key de OpenAI en el archivo .env o ingr√©sala en el panel lateral")
                return
            
            # Iniciar an√°lisis
            with st.spinner("Preparando an√°lisis..."):
                # Dividir en chunks
                chunks, total_comments = split_dataframe_into_chunks(
                    df_cleaned, 
                    comment_column="Cuerpo",
                    chunk_size=config['chunk_size'],
                    max_comments=config['max_comments']
                )
            
            # Crear sistema de seguimiento de progreso
            total_steps = len(chunks) + 1  # +1 para el an√°lisis final
            progress_bar, progress_text, update_progress = progress_tracker(total_steps)
            
            # Procesar chunks
            chunk_analyses = []
            
            for i, chunk in enumerate(chunks):
                update_progress(i, f"Analizando grupo {i+1} de {len(chunks)} ({len(chunk)} comentarios)...")
                
                # An√°lisis del chunk
                chunk_result = openai_service.analyze_comments_chunk(
                    chunk,
                    system_prompt=config['system_prompt'],
                    model=config['model'],
                    reasoning_effort=config['reasoning_effort']
                )
                
                # Verificar si hubo errores
                if chunk_result.get("error", False):
                    st.error(f"Error al analizar grupo {i+1}: {chunk_result.get('analysis', 'Error desconocido')}")
                    continue
                
                chunk_analyses.append(chunk_result)
                
                # Actualizar barra de progreso
                update_progress(i + 1, f"Grupo {i+1} de {len(chunks)} completado")
            
            # An√°lisis final
            update_progress(len(chunks), "Generando an√°lisis final...")
            
            with st.spinner("Generando an√°lisis final..."):
                final_analysis = openai_service.generate_final_analysis(
                    chunk_analyses,
                    total_comments=total_comments,
                    chunks_count=len(chunks),
                    system_prompt=config['system_prompt'],
                    model=config['model'],
                    reasoning_effort=config['reasoning_effort']
                )
            
            # Actualizar progreso final
            update_progress(total_steps, "An√°lisis completado")
            
            # Verificar si el an√°lisis final tuvo errores
            if final_analysis.get("error", False):
                st.error(f"Error en el an√°lisis final: {final_analysis.get('analysis', 'Error desconocido')}")
                return
            
            # Mostrar mensaje de √©xito
            st.success(f"‚úÖ An√°lisis completado: {total_comments} comentarios procesados en {len(chunks)} grupos")
            
            # Calcular totales de tokens
            token_counts = calculate_total_tokens(chunk_analyses + [final_analysis])
            
            # Mostrar m√©tricas generales
            metrics_display(
                total_comments=total_comments,
                tokens_reasoning=token_counts["tokens_reasoning"],
                total_tokens=token_counts["total_tokens"]
            )
            
            # Separador
            st.markdown("---")
            
            # Procesar y guardar resultados
            try:
                # Extraer m√©tricas para visualizaci√≥n
                metrics = extract_metrics_from_analysis(final_analysis["analysis"])
                
                # Extraer secciones clave
                sections = extract_key_sections(final_analysis["analysis"])
                
                # Formatear secciones para mejor presentaci√≥n
                formatted_sections = format_analysis_sections(sections)
                
                # Guardar an√°lisis en archivo
                filename = file_service.save_analysis_to_file(final_analysis["analysis"])
                
                # Mostrar resultados en pesta√±as
                results_tabs(
                    analysis_text=final_analysis["analysis"],
                    metrics=metrics,
                    formatted_sections=formatted_sections,
                    filepath=filename
                )
                
                # Guardar resultados en estado de sesi√≥n para referencia futura
                st.session_state.analysis_results = {
                    "analysis_text": final_analysis["analysis"],
                    "metrics": metrics,
                    "token_counts": token_counts,
                    "total_comments": total_comments,
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
            except Exception as processing_error:
                logger.error(f"Error al procesar resultados: {str(processing_error)}")
                st.error("Se complet√≥ el an√°lisis, pero hubo un error al procesar los resultados para visualizaci√≥n")
                st.text_area("An√°lisis en texto plano:", final_analysis["analysis"], height=400)
    
    except Exception as e:
        logger.error(f"Error al procesar archivo: {str(e)}", exc_info=True)
        error_message(e)

def render_help_page() -> None:
    """Renderiza la p√°gina de ayuda."""
    st.title("üìö Ayuda y Documentaci√≥n")
    
    st.markdown("""
    ## üîç An√°lisis de Sentimiento de Comentarios
    
    Esta aplicaci√≥n te permite analizar comentarios de clientes para extraer insights valiosos
    que pueden ayudarte a mejorar tus productos y estrategias de marketing.
    
    ### üìä Caracter√≠sticas principales
    
    - **An√°lisis de sentimiento**: Identifica la distribuci√≥n de comentarios positivos, negativos y neutrales
    - **Extracci√≥n de temas**: Descubre los temas m√°s mencionados por tus clientes
    - **Identificaci√≥n de fortalezas**: Conoce qu√© aspectos de tu producto son valorados positivamente
    - **Detecci√≥n de √°reas de mejora**: Identifica oportunidades para mejorar tus productos
    - **Ideas de marketing**: Recibe sugerencias para campa√±as basadas en los comentarios
    - **Segmentaci√≥n de clientes**: Identifica diferentes segmentos seg√∫n sus preferencias
    - **Recomendaciones accionables**: Obt√©n acciones concretas para mejorar la satisfacci√≥n del cliente
    
    ### üìã Requisitos del archivo CSV
    
    El archivo CSV debe contener al menos una columna llamada 'Cuerpo' (o el nombre que especifiques 
    en la configuraci√≥n) que contenga los comentarios a analizar.
    
    ### ‚öôÔ∏è Opciones de configuraci√≥n
    
    - **Tama√±o de chunk**: Define cu√°ntos comentarios se procesan juntos (10-200)
    - **M√°ximo de comentarios**: Limita el n√∫mero total de comentarios a analizar
    - **Modelo**: Selecciona el modelo de OpenAI a utilizar
    - **Esfuerzo de razonamiento**: Ajusta la profundidad del an√°lisis
    - **Instrucciones personalizadas**: Modifica las instrucciones enviadas al modelo
    
    ### üîê Configuraci√≥n de API Key
    
    Para usar esta aplicaci√≥n, necesitas configurar tu API Key de OpenAI:
    
    1. Crea un archivo `.env` en el directorio principal
    2. A√±ade tu API Key: `OPENAI_API_KEY=tu_api_key_aqu√≠`
    
    Alternativamente, puedes ingresar tu API Key en el panel lateral.
    """)
    
    st.markdown("---")
    
    with st.expander("‚ùì Preguntas frecuentes", expanded=False):
        st.markdown("""
        **P: ¬øCu√°ntos comentarios puedo analizar a la vez?**
        
        R: No hay un l√≠mite estricto, pero para obtener mejores resultados y controlar 
        los costos, recomendamos analizar entre 100 y 1000 comentarios a la vez.
        
        **P: ¬øC√≥mo afecta el tama√±o de chunk al an√°lisis?**
        
        R: Un tama√±o de chunk mayor reduce el n√∫mero de llamadas a la API pero puede
        hacer que el an√°lisis sea menos detallado. Un tama√±o menor permite un an√°lisis
        m√°s granular pero aumenta el n√∫mero de llamadas y el costo total.
        
        **P: ¬øC√≥mo puedo personalizar el an√°lisis?**
        
        R: Puedes modificar las instrucciones en el panel lateral para enfocar el an√°lisis
        en aspectos espec√≠ficos o ajustar el tipo de insights que deseas obtener.
        
        **P: ¬øQu√© formatos de archivo son compatibles?**
        
        R: Actualmente solo se admiten archivos CSV. Aseg√∫rate de que tu archivo tenga 
        una columna con los comentarios.
        """)

# Puedes a√±adir m√°s funciones para renderizar p√°ginas adicionales seg√∫n sea necesario